The term **Memory Tiering** refers to data placement between multiple
types of memory in order to take advantage of the most useful attributes
of each type.  For example, tiering between DRAM and Optane is done to
leverage the higher performance of DRAM with the cheaper capacity of Optane.
The most common reason for Memory Tiering configurations is cost
reduction because if cost isn't an issue, one could just populate the
entire system with the fastest type of memory available.  However, in
some cases tiering is used to provide capacities otherwise unavailable,
for example creating a 6 TB main memory system using 512 GB Optane modules
when 512 GB DRAM modules are not yet available.

Memory Tiering can be done by modifying the application to perform the
data placement in the appropriate tiers.  [libmemkind](#libmemkind) is
commonly used to provide malloc-like interfaces to such applications.
The [libnuma library](https://man7.org/linux/man-pages/man3/numa.3.html)
provides a lower-level, page-based interface for application-aware
memory tiering.

Memory Tiering can also be done in a way that is transparent to applications.
A hardware implementation of this is [Memory Mode](#memory-mode).  Software
implementations of transparent Memory Tiering include the experimental
[Linux Memory Tiering](https://git.kernel.org/pub/scm/linux/kernel/git/vishal/tiering.git/tree/README-tiering.txt?h=tiering-0.72),
and the [MemVerge product](https://www.memverge.com/).

Do not confuse Memory Tiering with [Memory Pooling](#memory-pooling), which is
a different concept.  The two concepts can work together, though, for example
if memory accessed from a pool has high latency, a platform could use
Memory Tiering to cache data from the pooled memory in a lower-latency
tier such as local DRAM.
